{"cells":[{"cell_type":"markdown","source":["#main.ipynb에서 사용할 모듈 clone\n","\n","\n","1.   preprocess.py\n","\n","    *   save_pickle - utils.py에 저장해둔 make_id_file 메소드를 이용해 tokenizer로 학습데이터셋을 토큰화 시킨 뒤 pickle 라이브러리를 이용해 토큰화 된 데이터를저장.\n","    *   load_pickle - temp라는 빈 리스트에 pickle 파일을 열어 파일 내부의 데이터를저장해 리턴해줌.\n","    *   data2dataset - *'bert-base-unbased'* 토크나이저를 load하고 현재 작업공간에 data set이 없다면 save_pickle 메소드로 데이터셋을 저장해주고 data set이 있는 경우에는 load_pickle로 데이터를 불러와 train set과 valid set을 구분하여 utils.py에 저장해둔 SentimentDataset 클래스로 각 데이터셋을 선언. test set에 대한 데이터도 마찬가지로 utils.py에서 불러와 처리해준 뒤 최종적으로 train_dataset, dev_dataset, test_dataset, test_df를 리턴.\n","\n","\n","2.   utils.py \n","\n","    *   baseline 코드에 있던 make_id_file & make_id_file_test, SentimentDataset class, collate_fn_style, compute_acc을 저장해둔 모듈. 추가적으로 sklearn패키지에서 제공하는 train_test_split을 이용한 get_small_sample 메소드 추가. \n","\n","\n","3.   data file\n","\n","\n","*   baseline에서 주어진 dataset 5가지와(sentiment_dev0 & 1, train 0 & 1, test_no_label)preprocess.py 에서 저장한 pkl파일들이 저장된 폴더.\n","\n","\n","\n","\n","\n","참고 사이트\n","\n","(pickle이란?)https://docs.python.org/ko/3/library/pickle.html\n","\n"],"metadata":{"id":"WBqW8kRkZ2Es"}},{"cell_type":"code","source":["# this was the first time i ever cried from a haircut .\n","\n","[\"not so great food and service .\"]\n","\n","[let me give my opinion , that 's what this site is for .]\n","\n","[the beer was nice and cold !]\n","\n","[there are better happy hours and better beers all around mill !]\n","\n","[it did n't matter of she is good at all other times .]\n","\n","[found the place even though it is hard due to bad signage .]\n","\n","[bottom line they over promise and under deliver .]\n","\n","[they can thank you for the low rating .]\n","\n","[the mechanics are very amateur as usual .]\n","\n","[actually , just keep walking .]\n","\n","[but being a tucson native this place brought nostalgia via my tastebuds .]\n","\n","[if you are looking to walk out transformed this is your place !]\n","\n","[his humor makes a routine visit entertaining .]\n","\n","[this spot was my favorite indian restaurant .]\n","\n","[tires , alignment , brakes and more .]\n","\n","[for the record i am a good cook , i use seasoning !]\n","\n","[sometimes it 's a simple cut , other times is more complicated color .]\n","\n","[it is a half a day trip from phoenix area .]\n","\n","[incredible , low price specials and the occasional groupon .]\n","\n","[that comes with the smaller location though .]\n","\n","[simply , there are far superior places to go for sushi .]\n"," \n","[tonight though i ordered to go and the food was just as good .]\n","\n","[blue corn tacos with chicken were excellent .]\n","\n","[its not cheap but you get good value here .]"],"metadata":{"id":"xIew8lIHJf_Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3228,"status":"ok","timestamp":1658059974170,"user":{"displayName":"조동일","userId":"13043427476096709949"},"user_tz":-540},"id":"GRiOjU4Eqzt8","outputId":"6d7b8304-88be-4351-af2a-c2cf9c93881f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'goorm_nlp_project_1'...\n","remote: Enumerating objects: 65, done.\u001b[K\n","remote: Counting objects: 100% (55/55), done.\u001b[K\n","remote: Compressing objects: 100% (30/30), done.\u001b[K\n","remote: Total 65 (delta 24), reused 47 (delta 23), pack-reused 10\u001b[K\n","Unpacking objects: 100% (65/65), done.\n"]}],"source":["!git clone https://github.com/22eming/goorm_nlp_project_1.git"]},{"cell_type":"markdown","source":["git에서 해당 파일들이 있는 카테고리로 이동"],"metadata":{"id":"g2fq-YIkaZS_"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1658059981347,"user":{"displayName":"조동일","userId":"13043427476096709949"},"user_tz":-540},"id":"QsCHVNNmQ0Pv","outputId":"985a3bee-14d5-4bd7-8b40-afad3770d612"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/goorm_nlp_project_1\n"]}],"source":["%cd /content/goorm_nlp_project_1"]},{"cell_type":"markdown","source":["##wandb install"],"metadata":{"id":"ApaxByG3h45t"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16014,"status":"ok","timestamp":1657981233576,"user":{"displayName":"조동일","userId":"13043427476096709949"},"user_tz":-540},"id":"mLcn7-u2mJdS","outputId":"23113b81-61fb-4052-9ea0-f63f6972188e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 7.4 MB/s \n","\u001b[?25hCollecting wandb\n","  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 38.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 40.9 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 55.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 12.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.7.2-py2.py3-none-any.whl (147 kB)\n","\u001b[K     |████████████████████████████████| 147 kB 58.5 MB/s \n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 50.8 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting setproctitle\n","  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=da68e6aefa39272f89bd72a172b6a04cf796f40c241b827007f0939c1401ba90\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, pyyaml, gitdb, tokenizers, shortuuid, setproctitle, sentry-sdk, pathtools, huggingface-hub, GitPython, docker-pycreds, wandb, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 huggingface-hub-0.8.1 pathtools-0.1.2 pyyaml-6.0 sentry-sdk-1.7.2 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 tokenizers-0.12.1 transformers-4.20.1 wandb-0.12.21\n"]}],"source":["!pip install transformers wandb"]},{"cell_type":"markdown","source":["##필요 패키지 및 라이브러리 import"],"metadata":{"id":"tP8YdOihiAii"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8avW5ODWmBVo"},"outputs":[],"source":["import os\n","import pdb\n","import argparse\n","from dataclasses import dataclass, field\n","from typing import Optional\n","from collections import defaultdict\n","import torch\n","from torch.nn.utils.rnn import pad_sequence\n","import torch.nn.functional as F\n","\n","import numpy as np\n","from tqdm import tqdm, trange\n","\n","from transformers import (\n","    BertForSequenceClassification,\n","    BertTokenizer,\n","    AutoConfig,\n","    AdamW\n",")\n","\n","from preprocess import data2dataset\n","from utils import collate_fn_style, collate_fn_style_test, compute_acc, get_small_sample"]},{"cell_type":"markdown","metadata":{"id":"kvrniyZGOTLJ"},"source":["# parameters 사용 예시 \n","##상수\n","\n","```\n","parameter_name:\n","    distribution: constant\n","    value: 2.71828\n","\n","```\n","\n","##범주\n","\n","```\n","  parameter_name:\n","    distribution: categorical\n","    values:\n","      - elu\n","      - celu\n","```\n","##uniform\n","```\n","  parameter_name:\n","    distribution: uniform\n","    min: 0\n","    max: 1\n","```\n","##quniform\n","```\n","  parameter_name:\n","    distribution: q_uniform\n","    min: 0\n","    max: 256\n","    q: 1\n","```\n","\n","##else\n","\n","```\n","parameters: {          \n","        epochs: {\n","            values: [10, 20, 50]\n","        },\n","```"]},{"cell_type":"markdown","source":["wandb sweep에 필요한 자료 config"],"metadata":{"id":"BezMe1SYiHtH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mt-KGNCKKjr0"},"outputs":[],"source":["sweep_config = {\n","    'method': 'bayes', # grid, random, bayes 중 선택\n","    'metric': {\n","      'name': 'val_loss',   # 목표 변수\n","      'goal': 'minimize'    # 목표\n","    },\n","    'parameters': {         # 조절하고 싶은 파라미터 \n","        'epochs': {\n","            'values': [1, 2, 3]\n","        },\n","        'dropout': {\n","            'values': [0.3, 0.4, 0.5]\n","        },\n","        'weight_decay': {\n","            'values': [0.0005, 0.005, 0.05]\n","        },\n","        'learning_rate': {\n","            'values': [1e-3, 1e-4, 3e-4, 3e-5, 1e-5]\n","        },\n","    }\n","}"]},{"cell_type":"markdown","metadata":{"id":"Ks1PXUxGPj5p"},"source":["## wandb import 및 sweep 실행.\n","project_name에 프로젝트 이름을 넣어주셔야 해당 프로젝트에 sweep이 생성됩니다!\n","\n","Sweep Guide(by 혁기 & 정환)\n","https://www.notion.so/AutoML-Guide-sweep-2d6ae4fd307544ee87a4eb5affd43bac\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"elapsed":6262,"status":"ok","timestamp":1657981318765,"user":{"displayName":"조동일","userId":"13043427476096709949"},"user_tz":-540},"id":"lUPwXCg8mBVt","outputId":"bce71b1f-4367-43f4-cdbe-ed55500945dc"},"outputs":[{"data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"name":"stdout","output_type":"stream","text":["Create sweep with ID: vfzw2gho\n","Sweep URL: https://wandb.ai/goorm_nlp_project_1/dongil_sweep_test/sweeps/vfzw2gho\n"]}],"source":["import wandb\n","progect_name = \"dongil_sweep_test\"\n","sweep_id = wandb.sweep(sweep_config, entity=\"goorm_nlp_project_1\", project=progect_name)"]},{"cell_type":"markdown","metadata":{"id":"cJj7m9RbmBVu"},"source":["# 데이터셋 가져오기"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["8e811ddeb77c47319205c5c1e99948e8","30159658dfd74fe68e14779755dbbdf3","5952989551fb4d17a7e58447ad80616b","52741614e6e64d179cf25f27cc8761ba","d3b78274c4de47928581c83859b93a5c","2792c10f38b945f48309cc646fc780cf","ea1c8602a5e94537a26344241f42a498","640eeaabc8e04ef5812a6a63ffd94443","cfbac8a770844234ad6c5ac39b93d296","f68c96fbf10c4cbc8f967aaff7ad62d9","3da2ee51be314b02ab012a3da12a8dcf","f4838d29fdeb4e59bc2f07861326fef9","f98585069f3a4dbebade1005a76cd6a7","99e7c1e45f3847bd8d8801380fccef9b","c08049e35d5943929ba8b5deb0c46ca8","7793409f91c04abe882ff2feeeb1fe26","8f87b99dc45c40478de5e465c33c3b40","596961e5272149368e70514494026911","96f9276f06b1484da0a3c23157afd25b","6ea1ea3d9035492c8a91eafd94d890d3","94d97c16dd21438e99a399031475105a","77a6fe5ad1fc40db9dac903ee1d0d30a","6eb3b1ee66f14755aafe4c688a1ebf7b","5b5a37d72d394ba2b8f60c2e73866c44","45cf01b4cf63438c9199cc07d3c9a457","5839eea5f7dc455490f956d5be01ae67","78cccc97d24746adabfe568f51af095d","abbb92496dff44bf96a157067f853d3c","842a744df25549beb4bb6bec3aabaafe","e075aadbcde84099863d0d282d081335","5614a64d0ac741afaa745b917eb892ee","f0781533f9044a18a5c63a788d5d4b9c","8a69810459bd4f4e8fc1a44afe622e36"]},"executionInfo":{"elapsed":8651,"status":"ok","timestamp":1657981333092,"user":{"displayName":"조동일","userId":"13043427476096709949"},"user_tz":-540},"id":"PU9y6uX_mBVu","outputId":"ece37d07-1c3a-461f-e930-01c8df6e0e3a"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e811ddeb77c47319205c5c1e99948e8","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4838d29fdeb4e59bc2f07861326fef9","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6eb3b1ee66f14755aafe4c688a1ebf7b","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_dataset, dev_dataset, test_dataset, test_df = data2dataset()\n","# 데이터세트, 가져올 비율\n","'''\n","    def get_small_sample(dataset, getting_size = 0.2):\n","        _, small_sample = train_test_split(dataset, test_size=getting_size, random_state=42)\n","        return small_sample\n","    \n","    train_test_split 은 sklearn 패키지에서 제공하는 메소드로 일반적으로 실무에서 train set과 test 셋에 대한 \n","    data를 따로 가져오지 않기 때문에 전체 데이터 셋을 해당 메소드로 나누어 많이 사용하게 됨.\n","    일반적으론 Train/Valid/Test 셋에 대해 6:2:2 정도의 비율을 사용하게 됨. \n","    \n","    위에 사용된 get_small_sample의 경우 단순히 전체 데이터 셋 양을 줄여 적은양의 샘플로 학습하고자 하는 목적이므로\n","    test set으로 분류된 data정보만 small_sample 변수에 저장하여 사용.\n","\n","    일반적인 예시)\n","    from sklearn.model_selection import train_test_split\n","\n","    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2, shuffle=True)\n","'''\n","train_dataset = get_small_sample(train_dataset, 0.2)"]},{"cell_type":"markdown","metadata":{"id":"9CW_zBDcmBVw"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EW4PJSiImBVw"},"outputs":[],"source":["#sweep.agent()에 파라미터로 넣어 sweep을 실행하고자 기본 베이스라인 코드에서 메소드로 형태를 변환하여 사용.\n","def train():\n","  lowest_valid_loss = 9999. #새로운 loss값과의 비교를 통해 가장 작은 loss를 찾아야 하므로 최솟값을 충분히 크게 설정.\n","\n","  # preprocess\n","  # config 변경 가능\n","  config_defaults = {\n","    'epochs': 2,\n","    'batch_size': 128,\n","    'weight_decay': 0.0005,\n","    'learning_rate': 1e-5,\n","    'optimizer': 'AdamW',\n","    'seed': 42,\n","    'tr_loss_check' : 50\n","  }\n","  '''\n","  sweep 과정에서 분할 된 실험 셋에 대해 각각 wandb 정보를 init해야하므로 wand.init을 train 함수 내부로 옮기고\n","  모델의 configuration을 wandb와 동일하게 설정.\n","  '''\n","  wandb.init(config=config_defaults)\n","  config = wandb.config\n","  '''\n","    모델에 데이터를 미니배치 형태로 넣기 수월하게 하기 위해 Pytorch의 데이터로더에 데이터를 넣어주는 작업이다.\n","    DataLoader에 대한 설명 대신 본인이 직접 보고 이해했던 블로그 주소 링크 첨부.(길어질수 있어서)\n","    https://sanghyu.tistory.com/90\n","  '''\n","  train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                           batch_size=config.batch_size,\n","                                           shuffle=True, collate_fn=collate_fn_style,\n","                                           pin_memory=True, num_workers=2)\n","  dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=config.batch_size,\n","                                         shuffle=False, collate_fn=collate_fn_style,\n","                                         num_workers=2)\n","  \"\"\"\n","\n","    학습 중 사용될 랜덤 변수들에 대해 seed를 정해주는 작업이다.\n","    seed를 설정하지 않으면 기본적으로 '시간'을 기준으로 내부 알고리즘에 따라 계속해서 난수를 생성하는데\n","    시간은 계속 흐르고 있기 때문에 난수를 생성하는 기준이 되는 seed또한 계속해서 바뀌게 된다.\n","    때문에 seed를 parameter로 지정하여 넘겨줌으로써 seed 값을 고정하여 같은 기준(seed)에서 난수가 생성되게끔 해주는 역할을 한다.\n","\n","  \"\"\"\n","  np.random.seed(config.seed)\n","  torch.manual_seed(config.seed)\n","\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 모델의 학습작업을 메소드를 통해 gpu가 사용 가능한 경우엔 gpu(cuda)에 올려 학습\n","\n","  model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n","  model.to(device) #모델을 위에서 설정한 device에 올림.\n","\n","  model.train() #train 모드로 변경.\n","\n","  optimizer = AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay) #optimizer 설정\n","\n","  # train()\n","  for epoch in range(config.epochs):\n","      with tqdm(train_loader, unit=\"batch\") as tepoch: #tqdm -> 상태 진행률을 프로세스바를 통해 시간적으로 확인할 수 있는 이터레이터 객체를 반환.\n","          for iteration, (input_ids, attention_mask, token_type_ids, position_ids, labels) in enumerate(tepoch):\n","              tepoch.set_description(f\"Epoch {epoch}\")\n","              #각 값들에 대한 input Tensor들 호출.\n","              input_ids = input_ids.to(device)\n","              attention_mask = attention_mask.to(device)\n","              token_type_ids = token_type_ids.to(device)\n","              position_ids = position_ids.to(device)\n","              labels = labels.to(device, dtype=torch.long)\n","              \n","              optimizer.zero_grad() \n","              \"\"\"\n","                pytorch의 경우 gradients값을 backward()를 통해 계산할때마다 기존 값에 계속 더해주는 방식으로 연산이\n","                진행되기 때문에 backpropagation 작업시마다 optimizer의 gradients를 0으로 초기화시켜주지 않으면 한번의\n","                iteration이 끝날 때마다 이전의 graidients값이 남아있어 학습이 제대로 진행되지 않습니다.\n","              \"\"\"\n","\n","              output = model(input_ids=input_ids,\n","                            attention_mask=attention_mask,\n","                            token_type_ids=token_type_ids,\n","                            position_ids=position_ids,\n","                            labels=labels)\n","              #model의 출력값에서의 loss를 backpropagation.\n","              loss = output.loss\n","              loss.backward()\n","              \n","              optimizer.step() #optimizer update\n","\n","              tepoch.set_postfix(loss=loss.item()) #콘솔에 결과 출력용\n","              \n","              #중간중간 train set에 대한 acc와 로스를 출력하기 위한 부분. config에 check할 iteration 단위를 저장하여 사용.\n","              if iteration % config.tr_loss_check == 0:\n","                logits = output.logits\n","                batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n","                batch_labels = [int(example) for example in labels]\n","                acc = compute_acc(batch_predictions, batch_labels)\n","                wandb.log({\"train_loss\" : loss, \"train_acc\" : acc})\n","                \n","              if iteration != 0 and iteration % int(len(train_loader) / 5) == 0:\n","                  # 한 epoch에서 5개의 시점으로 나누어 5번의 validation 진행.\n","                  with torch.no_grad():  \n","                      '''\n","                        validation 과정에서는 gradients를 다룰 필요가 없기 때문에 Pytorch 내부의 autograd engine을 꺼줌으로서\n","                        validation 과정에서의 연산 속도를 올리는게 주요 목적.\n","                      '''\n","                      model.eval() #validataion 모드로 변경.\n","                      valid_losses = []\n","                      predictions = []\n","                      target_labels = []\n","                      for input_ids, attention_mask, token_type_ids, position_ids, labels in tqdm(dev_loader,\n","                                                                                                  desc='Eval',\n","                                                                                                  position=1,\n","                                                                                                  leave=None):\n","                          #위와 마찬가지로 input Tensor값을 호출해 모델에 넣어 output 저장(line 110-120)\n","                          input_ids = input_ids.to(device)\n","                          attention_mask = attention_mask.to(device)\n","                          token_type_ids = token_type_ids.to(device)\n","                          position_ids = position_ids.to(device)\n","                          labels = labels.to(device, dtype=torch.long)\n","\n","                          output = model(input_ids=input_ids,\n","                                        attention_mask=attention_mask,\n","                                        token_type_ids=token_type_ids,\n","                                        position_ids=position_ids,\n","                                        labels=labels)\n","\n","                          logits = output.logits\n","                          loss = output.loss\n","                          valid_losses.append(loss.item())\n","\n","                          batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n","                          batch_labels = [int(example) for example in labels]\n","\n","                          predictions += batch_predictions\n","                          target_labels += batch_labels\n","\n","                  acc = compute_acc(predictions, target_labels)\n","                  valid_loss = sum(valid_losses) / len(valid_losses) #전체 valid set에 대한 loss값을 계산.\n","                  wandb.log({\"val_acc\":acc, \"val_loss\" : valid_loss})\n","                  if lowest_valid_loss > valid_loss: #최적 시점의 모델을 저장하는 구문 baseline 코드에선 validation loss가 가장 낮은곳으로 기준을 설정.\n","                      print('Acc for model which have lower valid loss: ', acc)\n","                      torch.save(model.state_dict(), \"./pytorch_model.bin\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"kUD9OarhWg01"},"outputs":[],"source":["#위에 설정한 train 메소드를 넣어주어 설정한 여러 하이퍼 파라미터별로 나누어 sweep 실행.\n","wandb.agent(sweep_id, train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YoqQGm6RmBVx"},"outputs":[],"source":["test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=config.batch_size,\n","                                          shuffle=False, collate_fn=collate_fn_style_test,\n","                                          num_workers=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nhIkp5q3mBVx","outputId":"0f81722c-d2f2-415c-d39d-0750cc38fae0"},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","Test:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n","Test:   6%|▋         | 1/16 [00:00<00:01,  7.59it/s]\u001b[A\n","Test:  19%|█▉        | 3/16 [00:00<00:00, 13.42it/s]\u001b[A\n","Test:  31%|███▏      | 5/16 [00:00<00:00, 15.86it/s]\u001b[A\n","Test:  50%|█████     | 8/16 [00:00<00:00, 18.36it/s]\u001b[A\n","Test:  69%|██████▉   | 11/16 [00:00<00:00, 19.48it/s]\u001b[A\n","Test:  88%|████████▊ | 14/16 [00:00<00:00, 20.11it/s]\u001b[A\n","                                                     \u001b[A"]}],"source":["with torch.no_grad():\n","    model.eval()\n","    predictions = []\n","    for input_ids, attention_mask, token_type_ids, position_ids in tqdm(test_loader,\n","                                                                        desc='Test',\n","                                                                        position=1,\n","                                                                        leave=None):\n","\n","        input_ids = input_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        token_type_ids = token_type_ids.to(device)\n","        position_ids = position_ids.to(device)\n","\n","        output = model(input_ids=input_ids,\n","                       attention_mask=attention_mask,\n","                       token_type_ids=token_type_ids,\n","                       position_ids=position_ids)\n","\n","        logits = output.logits\n","        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n","        predictions += batch_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8YXn5ogfmBVx"},"outputs":[],"source":["test_df['Category'] = predictions\n","test_df.to_csv('submission.csv', index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"main.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.12 ('sawol')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"52439c17ae9e7865010b23f3ecb0a061945370b287a07a5a21a615abca8bb4c6"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"2792c10f38b945f48309cc646fc780cf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30159658dfd74fe68e14779755dbbdf3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2792c10f38b945f48309cc646fc780cf","placeholder":"​","style":"IPY_MODEL_ea1c8602a5e94537a26344241f42a498","value":"Downloading: 100%"}},"3da2ee51be314b02ab012a3da12a8dcf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45cf01b4cf63438c9199cc07d3c9a457":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e075aadbcde84099863d0d282d081335","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5614a64d0ac741afaa745b917eb892ee","value":570}},"52741614e6e64d179cf25f27cc8761ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f68c96fbf10c4cbc8f967aaff7ad62d9","placeholder":"​","style":"IPY_MODEL_3da2ee51be314b02ab012a3da12a8dcf","value":" 226k/226k [00:00&lt;00:00, 924kB/s]"}},"5614a64d0ac741afaa745b917eb892ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5839eea5f7dc455490f956d5be01ae67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0781533f9044a18a5c63a788d5d4b9c","placeholder":"​","style":"IPY_MODEL_8a69810459bd4f4e8fc1a44afe622e36","value":" 570/570 [00:00&lt;00:00, 14.7kB/s]"}},"5952989551fb4d17a7e58447ad80616b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_640eeaabc8e04ef5812a6a63ffd94443","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cfbac8a770844234ad6c5ac39b93d296","value":231508}},"596961e5272149368e70514494026911":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b5a37d72d394ba2b8f60c2e73866c44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abbb92496dff44bf96a157067f853d3c","placeholder":"​","style":"IPY_MODEL_842a744df25549beb4bb6bec3aabaafe","value":"Downloading: 100%"}},"640eeaabc8e04ef5812a6a63ffd94443":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ea1ea3d9035492c8a91eafd94d890d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6eb3b1ee66f14755aafe4c688a1ebf7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b5a37d72d394ba2b8f60c2e73866c44","IPY_MODEL_45cf01b4cf63438c9199cc07d3c9a457","IPY_MODEL_5839eea5f7dc455490f956d5be01ae67"],"layout":"IPY_MODEL_78cccc97d24746adabfe568f51af095d"}},"7793409f91c04abe882ff2feeeb1fe26":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77a6fe5ad1fc40db9dac903ee1d0d30a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"78cccc97d24746adabfe568f51af095d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"842a744df25549beb4bb6bec3aabaafe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a69810459bd4f4e8fc1a44afe622e36":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e811ddeb77c47319205c5c1e99948e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30159658dfd74fe68e14779755dbbdf3","IPY_MODEL_5952989551fb4d17a7e58447ad80616b","IPY_MODEL_52741614e6e64d179cf25f27cc8761ba"],"layout":"IPY_MODEL_d3b78274c4de47928581c83859b93a5c"}},"8f87b99dc45c40478de5e465c33c3b40":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94d97c16dd21438e99a399031475105a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96f9276f06b1484da0a3c23157afd25b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99e7c1e45f3847bd8d8801380fccef9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_96f9276f06b1484da0a3c23157afd25b","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ea1ea3d9035492c8a91eafd94d890d3","value":28}},"abbb92496dff44bf96a157067f853d3c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c08049e35d5943929ba8b5deb0c46ca8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94d97c16dd21438e99a399031475105a","placeholder":"​","style":"IPY_MODEL_77a6fe5ad1fc40db9dac903ee1d0d30a","value":" 28.0/28.0 [00:00&lt;00:00, 754B/s]"}},"cfbac8a770844234ad6c5ac39b93d296":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d3b78274c4de47928581c83859b93a5c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e075aadbcde84099863d0d282d081335":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea1c8602a5e94537a26344241f42a498":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0781533f9044a18a5c63a788d5d4b9c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4838d29fdeb4e59bc2f07861326fef9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f98585069f3a4dbebade1005a76cd6a7","IPY_MODEL_99e7c1e45f3847bd8d8801380fccef9b","IPY_MODEL_c08049e35d5943929ba8b5deb0c46ca8"],"layout":"IPY_MODEL_7793409f91c04abe882ff2feeeb1fe26"}},"f68c96fbf10c4cbc8f967aaff7ad62d9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f98585069f3a4dbebade1005a76cd6a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f87b99dc45c40478de5e465c33c3b40","placeholder":"​","style":"IPY_MODEL_596961e5272149368e70514494026911","value":"Downloading: 100%"}}}}},"nbformat":4,"nbformat_minor":0}